{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "from nltk.parse import DependencyGraph\n",
    "from typing import List, Tuple, Dict\n",
    "import tqdm\n",
    "import spacy\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from collections import Counter\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"quora_duplicate_questions.tsv\", sep = \"\\t\")\n",
    "#df = df.head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>How can you make physics easy to learn?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>What was your first sexual experience?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>What would a Trump presidency mean for current...</td>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>What does manipulation mean?</td>\n",
       "      <td>What does manipulation means?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>Why are so many Quora users posting questions ...</td>\n",
       "      <td>Why do people ask Quora questions which can be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>Why do rockets look white?</td>\n",
       "      <td>Why are rockets and boosters painted white?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>How should I prepare for CA final law?</td>\n",
       "      <td>How one should know that he/she completely pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  qid1  qid2                                          question1  \\\n",
       "5    5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "7    7    15    16                     How can I be a good geologist?   \n",
       "11  11    23    24        How do I read and find my YouTube comments?   \n",
       "12  12    25    26               What can make Physics easy to learn?   \n",
       "13  13    27    28        What was your first sexual experience like?   \n",
       "15  15    31    32  What would a Trump presidency mean for current...   \n",
       "16  16    33    34                       What does manipulation mean?   \n",
       "18  18    37    38  Why are so many Quora users posting questions ...   \n",
       "20  20    41    42                         Why do rockets look white?   \n",
       "29  29    59    60             How should I prepare for CA final law?   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "5   I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "7           What should I do to be a great geologist?             1  \n",
       "11             How can I see all my Youtube comments?             1  \n",
       "12            How can you make physics easy to learn?             1  \n",
       "13             What was your first sexual experience?             1  \n",
       "15  How will a Trump presidency affect the student...             1  \n",
       "16                      What does manipulation means?             1  \n",
       "18  Why do people ask Quora questions which can be...             1  \n",
       "20        Why are rockets and boosters painted white?             1  \n",
       "29  How one should know that he/she completely pre...             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df[\"is_duplicate\"] == 1]\n",
    "question1, question2 = duplicates[\"question1\"].str.lower().tolist(), duplicates[\"question2\"].str.lower().tolist()\n",
    "duplicates.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(object):\n",
    "    \n",
    "    def __init__(self, device = 'cpu'):\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "        self.device = device\n",
    "        \n",
    "    def tokenize(self, original_sentence: List[str]) -> Tuple[List[str], Dict[int, int]]:\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        -------\n",
    "        bert_tokens: The sentence, tokenized by BERT tokenizer.\n",
    "        orig_to_tok_map: An output dictionary consisting of a mapping (alignment) between indices in the original tokenized sentence, and indices in the sentence tokenized by the BERT tokenizer. See https://github.com/google-research/bert\n",
    "        \"\"\"\n",
    "\n",
    "        bert_tokens = [\"[CLS]\"]\n",
    "        orig_to_tok_map = {}\n",
    "        has_subwords = False\n",
    "        is_subword = []\n",
    "\n",
    "        for i, w in enumerate(original_sentence):\n",
    "            tokenized_w = self.tokenizer.tokenize(w)\n",
    "            has_subwords = len(tokenized_w) > 1\n",
    "            is_subword.append(has_subwords)\n",
    "            bert_tokens.extend(tokenized_w)\n",
    "\n",
    "            orig_to_tok_map[i] = len(bert_tokens) - 1\n",
    "\n",
    "        bert_tokens.append(\"[SEP]\")\n",
    "        \n",
    "        return (bert_tokens, orig_to_tok_map)\n",
    "\n",
    "    \n",
    "    def encode(self, sentence: str):\n",
    "    \n",
    "        tokenized_text, orig2tok = self.tokenize(sentence.split(\" \"))\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens]).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor)\n",
    "            predictions = outputs[0].detach().cpu().numpy()[0,0, :] # take last hidden layer, the state over the CLS token\n",
    "            return (predictions.squeeze(), orig2tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertEncoder('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 57322/149263 [21:24<36:12, 42.31it/s] "
     ]
    }
   ],
   "source": [
    "states = []\n",
    "\n",
    "for q1, q2 in tqdm.tqdm(zip(question1, question2), total = len(question1)):\n",
    "    \n",
    "    v1, v2 = bert.encode(q1), bert.encode(q2)\n",
    "    states.append((v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_ids = duplicates[\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1,q2 = list(zip(*states))\n",
    "q1,_ = list(zip(*q1))\n",
    "q2,_ = list(zip(*q2))\n",
    "\n",
    "states_with_strings_and_ids = list(zip(q1,q2,question1,question2, pair_ids))\n",
    "with open(\"bert-base.cls.last-layer.pickle\", \"wb\") as f:\n",
    "    pickle.dump(states_with_strings_and_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(np_array):\n",
    "        return \"\\t\".join([\"%0.4f\" % x for x in np_array])\n",
    "    \n",
    "with open(\"vecs.tsv\", \"w\") as f:\n",
    "    for v in q1 + q2:\n",
    "        f.write(to_string(v[0]) + \"\\n\")\n",
    "\n",
    "with open(\"labels.tsv\", \"w\") as f:\n",
    "    for s in question1 + question2:\n",
    "        f.write(s + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
